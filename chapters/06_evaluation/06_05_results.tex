\section{実験結果}
\label{sec:experimental_results}

本節では、生成成功率、操作フローの正確性、生成の一貫性、生成時間、およびトークン効率の観点から実験結果を詳述する。

\subsection{生成成功率}
各モデルにおける生成成功率（構文エラーなく実行可能なコードが生成された割合）を表\ref{tab:success_rate}に示す。
GPT-4o は 30 回の試行中 28 回成功し、約 93.3\% という高い成功率を記録した。
一方、GPT-4o-mini の成功率は 70.0\% に留まった。
失敗の主な原因は、出力された JSON の形式不備（カンマの欠落やネスト構造の誤り）であり、
複雑なスキーマ定義を遵守する能力に関しては、ハイエンドモデルである GPT-4o が優位であることが確認された。

\begin{table}[tb]
  \centering
  \caption{モデルごとの生成成功率}
  \label{tab:success_rate}
  \begin{tabular}{l|rrr}
    \hline
    モデル & 試行回数 & 成功回数 & 成功率 \\
    \hline \hline
    GPT-4o & 30 & 28 & 93.3\% \\
    GPT-4o-mini & 30 & 21 & 70.0\% \\
    \hline
  \end{tabular}
\end{table}

\subsection{操作フローの正確性}

\begin{table}[tb]
  \centering
  \caption{操作フロー抽出の混同行列および精度評価}
  \label{tab:flow_accuracy_detail}
  \begin{tabular}{l|rrr|rrr}
    \hline
    モデル & TP & FP & FN & Precision & Recall & F1-score \\
    \hline \hline
    GPT-4o & 66 & 36 & 53 & 0.647 & 0.555 & 0.597 \\
    GPT-4o-mini & \textbf{76} & \textbf{12} & \textbf{23} & \textbf{0.864} & \textbf{0.768} & \textbf{0.813} \\
    \hline
  \end{tabular}
\end{table}

\subsubsection{操作抽出の適合率・再現率}
本評価実験において，API 生成プロセスが正常に完了したケースを分析対象とし， 
抽出された操作フロー（\texttt{steps}）が正解データとどの程度一致しているかについて定量的な評価を行った。
表\ref{tab:flow_accuracy_detail}には，評価指標として採用した 
True Positive (TP)，False Positive (FP)，False Negative (FN) の具体的な件数内訳を示す。 
さらに，これらの値に基づいて算出された適合率（Precision），再現率（Recall），
および総合的な精度を示す F1 スコアについても併せて掲載する。

表\ref{tab:flow_accuracy_detail}の結果から明らかであるように，
本タスクにおいては GPT-4o-mini が GPT-4o を大きく上回る性能を発揮し，
F1 スコアにおいて 0.813 という高い値を記録した。 
モデルごとの具体的な内訳を詳細に見ると，以下の顕著な特徴が確認された。

\begin{itemize}
  \item \textbf{GPT-4o の課題}: FN（抽出漏れ）が 53 件と非常に多い。これは、マニュアルに記載されている操作の約半数を見落としていることを意味する。また、FP（過剰抽出）も 36 件あり、存在しない操作を誤って生成する傾向も見られた。
  \item \textbf{GPT-4o-mini の特性}: FP が 12 件、FN が 23 件といずれも低い値に抑えられている。これは、マニュアルの記述に対して忠実であり、かつ必要な操作を網羅的に抽出できていることを示している。
\end{itemize}

一般にパラメータ数が多いモデルの方が性能が高いとされるが、特定のフォーマットに従って情報を抽出する本タスクにおいては、軽量モデルである GPT-4o-mini の方が高い抽出能力を示した。

\subsubsection{ステップ順序の正確性}
抽出された操作（TP）において、ボタンを押す順序などのステップ構成が正しいかを検証した。
結果として，両モデルともにステップ順序の正確性は極めて高く，
GPT-4o で 0.94，GPT-4o-mini で 0.95 という高水準な値を記録した。
この結果は，ひとたび操作の存在自体を正しく認識できさえすれば，
その後の具体的な手順（ステップ）の因果関係や前後関係については，
どちらのモデルもマニュアルの記述通りに正確に再現・生成できる能力を有していることを示唆している。

\subsection{生成の一貫性}
同一のマニュアルを複数回入力した際の出力の安定性を評価するため，フロー一致率を測定した結果を表\ref{tab:consistency}に示す。
実験の結果，GPT-4o-mini の平均一致率は 0.609 となり，GPT-4o (0.462) よりも有意に高い一貫性を示した。
一般に GPT-4o は高い表現力を持つとされるが，本タスクにおいてはその特性が裏目に出ている可能性がある。
すなわち，試行ごとに操作名の命名規則（例: \texttt{turnOn} と \texttt{powerOn} の揺らぎ）や手順の粒度解釈が変動しやすく，
これが構造化データの生成における不安定要因となっていると考えられる。

\begin{table}[t]
  \centering
  % --- 左側の表: 一貫性 ---
  \begin{minipage}[t]{0.48\linewidth}
    \centering
    \caption{生成結果の一貫性（フロー一致率）}
    \label{tab:consistency}
    \begin{tabular}{l|r}
      \hline
      モデル & 平均一致率 \\
      \hline \hline
      GPT-4o & 0.462 \\
      GPT-4o-mini & \textbf{0.609} \\
      \hline
    \end{tabular}
  \end{minipage}
  \hfill % ← ここで左右の間隔を調整
  % --- 右側の表: 生成時間 ---
  \begin{minipage}[t]{0.48\linewidth}
    \centering
    \caption{平均生成時間}
    \label{tab:generation_time}
    \begin{tabular}{l|r}
      \hline
      モデル & 平均時間 (秒) \\
      \hline \hline
      GPT-4o & \textbf{23.57} \\
      GPT-4o-mini & 31.10 \\
      \hline
    \end{tabular}
  \end{minipage}
\end{table}
\subsection{生成時間}
表\ref{tab:generation_time}に平均生成時間を示す。
本実験環境においては、GPT-4o が約 23.6 秒、GPT-4o-mini が約 31.1 秒となり、
パラメータ数の多い GPT-4o の方がむしろ高速に処理を完了するという結果が得られた。
後述するトークン数の内訳に基づくと、GPT-4o-mini は出力トークン数が非常に多いため、
生成にかかるレイテンシが増大したと考えられる。

\subsection{トークン効率}
1回のドライバ生成プロセスにおける平均消費トークン数の内訳（入力プロンプト、出力完了、合計）を表\ref{tab:token_breakdown}に示す。
一般に、軽量モデルである GPT-4o-mini はコスト効率に優れるとされるが、本研究においては、GPT-4o の方がより少ないトークン数で処理を完了できるという結果が得られた。

\begin{table}[tb]
  \centering
  \caption{平均消費トークン数の内訳 (Tokens/run)}
  \label{tab:token_breakdown}
  \begin{tabular}{l|rrr}
    \hline
    モデル & Input Tokens & Output Tokens & Total Tokens \\
    \hline \hline
    GPT-4o & \textbf{33,729} & \textbf{702} & \textbf{34,431} \\
    GPT-4o-mini & 40,160 & 860 & 41,020 \\
    \hline
  \end{tabular}
\end{table}

表\ref{tab:token_breakdown} の内訳に基づき、以下の特性が確認された。

\begin{itemize}
  \item \textbf{Input Tokens}: 
  同一のマニュアル（PDF）を入力しているにもかかわらず、GPT-4o (33,729) は GPT-4o-mini (40,160) と比較して約 16\% 少ないトークン数で入力を処理している。
  これは、GPT-4o のトークナイザが、日本語の技術文書や PDF に含まれる特殊文字に対して、より高い圧縮効率を持っていることを示唆している。

  \item \textbf{Output Tokens}:
  出力においても、GPT-4o (702) は GPT-4o-mini (860) より約 18\% 少ないトークン数で生成を完了している。
  両モデルともに構文的に正しい JSON を生成しようとするが、GPT-4o の方がより簡潔で無駄のない記述を行う能力に長けていると考えられる。
\end{itemize}

以上の結果から、単価（Cost per Token）においては GPT-4o-mini が安価であるが、処理するトークン総量（Volume）においては GPT-4o が効率的であることが明らかになった。
システム全体のレイテンシや、コンテキストウィンドウの消費を抑える観点では、ハイエンドモデルである GPT-4o の利用が有利に働くケースが存在するといえる。
