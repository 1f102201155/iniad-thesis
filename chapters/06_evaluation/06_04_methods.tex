\section{実験設定}
\label{sec:methods}

本節では、評価実験に用いたデータセット、比較対象モデル、および正解データの作成方法について述べる。

\subsection{データセットと試行回数}
評価対象として、SwitchBot 社製のスマート家電および関連デバイスの取扱説明書（PDF 形式）10 件を使用した。
対象デバイスには、物理ボット（スイッチ）、カーテン開閉装置、温湿度計、スマートプラグ、加湿器などが含まれ、
マニュアルの記述量や操作の複雑度は多岐にわたる。
各 PDF ファイルには \texttt{test01} から \texttt{test10} までの ID を付与し、実験の入力データとした。

LLM の出力には確率的な揺らぎが含まれるため、単一の試行ではモデルの性能を正確に評価できない可能性がある。
そこで本実験では、各 PDF に対して同一条件で 3 回ずつ生成を試行した。
したがって、1 モデルあたりの総試行回数は 30 回（10 ファイル $\times$ 3 回）、
2 モデル合計で 60 回の生成実験を行った。

\subsection{比較対象モデル}
本実験では、性能特性の異なる以下の 2 つのモデルを用いて比較を行った。

\begin{itemize}
  \item \textbf{GPT-4o}:
  OpenAPI が提供するハイエンドモデル。
  複雑な推論や文脈理解に優れており、マニュアルの微細な記述や複雑な条件分岐を正確に解釈する能力が期待される。
  \item \textbf{GPT-4o-mini}:
  GPT-4o の軽量版モデル。
  低コストかつ高速なレスポンスが特徴であるが、複雑な推論能力においては GPT-4o に劣る可能性がある。
  本研究では、IoT ドライバ生成という特定タスクにおいて、軽量モデルがどの程度実用的な性能を発揮できるかを検証する。
\end{itemize}

\subsection{正解データの作成}
「操作フローの正確性」を評価するために、各マニュアルの内容を精査し、期待される API 操作定義（正解データ）を手動で作成した。
正解データには、各デバイスで可能な操作（例: 「電源ON」「音量アップ」）と、その操作を実行するために必要なステップ（例: 「対象デバイスIDを指定して \texttt{turnOn} コマンドを送信」）を定義している。
生成された結果と比較する際は、操作名（Operation ID）の表記ゆれを許容しつつ、
実行されるステップの構成要素（コマンドの種類、対象パラメータ）が論理的に一致しているかを判定基準とした。
